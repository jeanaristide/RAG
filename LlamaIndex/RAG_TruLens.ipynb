{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_index.llms import AzureOpenAI\n",
    "from llama_index.embeddings import AzureOpenAIEmbedding\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "import logging\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.llms import Ollama\n",
    "import numpy as np\n",
    "from trulens_eval import TruLlama, Feedback, Tru, feedback\n",
    "from langchain.llms import Ollama\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "from trulens_eval import LiteLLM\n",
    "import litellm\n",
    "litellm.set_verbose=False\n",
    "tru = Tru()\n",
    "\n",
    "load_dotenv('/Users/jeana/.env')\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout, level=logging.WARNING\n",
    ")  # logging.DEBUG for more verbose output\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_location = [r\"/Users/jeana/Retrieval-Augmented-Generation/LlamaIndex/paul_graham_essay.txt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelException(Exception):\n",
    "    def __init__(self, invalid_value, allowed_values):\n",
    "        self.invalid_value = invalid_value\n",
    "        self.allowed_values = allowed_values\n",
    "        message = f\"Invalid value: {invalid_value}. Allowed values are: {', '.join(allowed_values)}\"\n",
    "        super().__init__(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Evaluator with Feedback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedbacks(llm_name):\n",
    "\n",
    "    ##### INITIALZE FEEDBACK FUNCTION(S)#######\n",
    "    if llm_name == 'azureoai':\n",
    "        # Initialize AzureOpenAI-based feedback function collection class:\n",
    "        llm_provider = feedback.AzureOpenAI(\n",
    "                                        deployment_name=os.environ['OPENAI_DEPLOYMENT_NAME'],\n",
    "                                        api_key = os.environ['OPENAI_API_KEY'],\n",
    "                                        api_version=os.environ['OPENAI_DEPLOYMENT_VERSION'],\n",
    "                                        azure_endpoint=os.environ['OPENAI_DEPLOYMENT_ENDPOINT'],\n",
    "                                        # model = os.environ['OPENAI_MODEL_NAME']\n",
    "                                        )\n",
    "    elif llm_name == 'llama2':\n",
    "        llm_provider = LiteLLM(model_engine=\"ollama/llama2\", api_base='http://localhost:11434')\n",
    "\n",
    "    # Question/answer relevance between overall question and answer.\n",
    "    f_qa_relevance = Feedback(llm_provider.relevance, name = \"Answer Relevance\").on_input_output()\n",
    "\n",
    "    # Question/statement relevance between question and each context chunk.\n",
    "    f_qs_relevance = Feedback(llm_provider.qs_relevance, name = \"Context Relevance\").on_input().on(\n",
    "        TruLlama.select_source_nodes().node.text\n",
    "    ).aggregate(np.mean)\n",
    "\n",
    "    # groundedness of output on the context\n",
    "    groundedness = feedback.Groundedness(\n",
    "                    # summarize_provider=azopenai, \n",
    "                    groundedness_provider=llm_provider)\n",
    "    f_groundedness = Feedback(groundedness.groundedness_measure, name = \"Groundedness\").on(TruLlama.select_source_nodes().node.text).on_output()\n",
    "    \n",
    "    feedbacks=[f_groundedness, f_qa_relevance, f_qs_relevance]\n",
    "    \n",
    "    return feedbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Context Relevance, input statement will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "feedbacks = feedbacks('llama2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG():\n",
    "    llm_list = ['llama2', 'gpt3.5Turbo']\n",
    "    embedding_list = ['text-embedding-ada-002', 'sentence-transformers/all-mpnet-base-v2', \"BAAI/bge-small-en-v1.5\"]\n",
    "\n",
    "    def __init__(self, llm_name, embedding_model, feedbacks):   \n",
    "        if llm_name not in self.llm_list:\n",
    "            raise modelException(llm_name, self.llm_list)\n",
    "        if embedding_model not in self.embedding_list:\n",
    "            raise modelException(embedding_model, self.embedding_list)        \n",
    "\n",
    "        ## Getting the LLM for prediction\n",
    "        if llm_name == 'gpt3.5Turbo':\n",
    "            self.llm = AzureOpenAI(\n",
    "                    # model= os.environ['OPENAI_MODEL_NAME'],\n",
    "                    model = llm_name,\n",
    "                    deployment_name= os.environ['OPENAI_DEPLOYMENT_NAME'],\n",
    "                    api_key=os.environ['OPENAI_API_KEY'],\n",
    "                    azure_endpoint=os.environ['OPENAI_DEPLOYMENT_ENDPOINT'],\n",
    "                    api_version=os.environ['OPENAI_DEPLOYMENT_VERSION'],\n",
    "                )\n",
    "        elif llm_name == 'llama2':\n",
    "            self.llm = Ollama(model=\"llama2\")\n",
    "        \n",
    "        ## Gettting the embedding model\n",
    "        if embedding_model == 'text-embedding-ada-002':\n",
    "            self.embedding_model = AzureOpenAIEmbedding(\n",
    "                    # model=os.environ['OPENAI_EMBEDDING_MODEL_NAME'],\n",
    "                    model=embedding_model,\n",
    "                    deployment_name=os.environ['OPENAI_EMBEDDING_DEPLOYMENT_NAME'],\n",
    "                    api_key=os.environ['OPENAI_API_KEY'],\n",
    "                    azure_endpoint=os.environ['OPENAI_DEPLOYMENT_ENDPOINT'],\n",
    "                    api_version=os.environ['OPENAI_DEPLOYMENT_VERSION'],\n",
    "                )\n",
    "        elif embedding_model in ['sentence-transformers/all-mpnet-base-v2', \"BAAI/bge-small-en-v1.5\"]:\n",
    "            self.embedding_model = HuggingFaceEmbeddings(\n",
    "                    model_name=embedding_model)\n",
    "        \n",
    "        #Set service context, documents and Index\n",
    "        self.service_context = ServiceContext.from_defaults(embed_model=self.embedding_model, llm = self.llm)\n",
    "\n",
    "        self.documents = SimpleDirectoryReader(\n",
    "                    input_files=[r\"/Users/jeana/Retrieval-Augmented-Generation/LlamaIndex/paul_graham_essay.txt\"] #or just indicate the fullpath of the folder containing the data\n",
    "                                ).load_data()\n",
    "        self.index = VectorStoreIndex.from_documents(self.documents, service_context=self.service_context)\n",
    "\n",
    "    def query(self, query: str) -> str:\n",
    "        ### INSTRUMENT CHAIN FOR LOGGING WITH TRULENS\n",
    "\n",
    "        query_engine = self.index.as_query_engine()\n",
    "\n",
    "        tru_query_engine_recorder = TruLlama(query_engine,\n",
    "                app_id='LlamaIndex_App1',\n",
    "                feedbacks=feedbacks)\n",
    "\n",
    "        with tru_query_engine_recorder as recorder:\n",
    "            answer = query_engine.query(query)\n",
    "            print(answer.get_formatted_sources())\n",
    "            print(\"query was:\", query)\n",
    "            print(\"answer was:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_name =  'llama2' #gpt3.5Turbo , llama2\n",
    "embedding_model = 'sentence-transformers/all-mpnet-base-v2' # text-embedding-ada-002 , sentence-transformers/all-mpnet-base-v2, local\n",
    "rag = RAG(llm_name, embedding_model, feedbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Source (Doc id: 40b903d0-3fcb-402b-9a2d-78657b3702fa): I remember taking the boys to the coast on a sunny day in 2015 and figuring out how to deal with ...\n",
      "\n",
      "> Source (Doc id: 84113d28-1844-4113-84ce-3cd7a96cc2c5): One of the most conspicuous patterns I've noticed in my life is how well it has worked, for me at...\n",
      "query was: What is most interesting about this essay?\n",
      "answer was: Based on the provided context, the most interesting aspect of this essay is the author's reflection on how they have chosen what to work on throughout their life. The author notes that they have always been drawn to working on things that were not prestigious at the time, such as still life painting, Viaweb, and Y Combinator. They also observe that when they find themselves interested in something despite its lack of prestige, it is a sign that there is something real to be discovered and that they have the right kind of motives. The author also shares personal anecdotes and experiences, such as their dinner parties and meeting Jessica Livingston, which led to them starting an investment firm together. Overall, the essay provides insight into the author's thought process and approach to work, and how they have managed to balance creativity and practicality throughout their career.\n",
      "WARNING:trulens_eval.feedback.groundedness:Feedback function `groundedness_measure` was renamed to `groundedness_measure_with_cot_reasons`. The new functionality of `groundedness_measure` function will no longer emit reasons as a lower cost option. It may have reduced accuracy due to not using Chain of Thought reasoning in the scoring.\n",
      "Feedback function `groundedness_measure` was renamed to `groundedness_measure_with_cot_reasons`. The new functionality of `groundedness_measure` function will no longer emit reasons as a lower cost option. It may have reduced accuracy due to not using Chain of Thought reasoning in the scoring.\n"
     ]
    }
   ],
   "source": [
    "rag.query('What is most interesting about this essay?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness:::full_doc_score</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LlamaIndex_App1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_428bceed859a74951403887e04431b27</td>\n",
       "      <td>\"What is most interesting about this essay?\"</td>\n",
       "      <td>\"The most interesting aspect of this essay is ...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_428bceed859a7495140...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-26T16:56:58.102181\", \"...</td>\n",
       "      <td>2023-12-26T16:57:29.004522</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'args': {'prompt': 'What is most interesting...</td>\n",
       "      <td>[{'args': {'question': 'What is most interesti...</td>\n",
       "      <td>[{'args': {'source': 'I remember taking the bo...</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LlamaIndex_App1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_2aab1c5faa398bff375bdfe7f6d897dd</td>\n",
       "      <td>\"What is most interesting about this essay?\"</td>\n",
       "      <td>\"Based on the provided context, the most inter...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_2aab1c5faa398bff375...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-26T17:33:45.205486\", \"...</td>\n",
       "      <td>2023-12-26T17:34:15.982798</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>[{'args': {'prompt': 'What is most interesting...</td>\n",
       "      <td>[{'args': {'question': 'What is most interesti...</td>\n",
       "      <td>[{'args': {'source': 'I remember taking the bo...</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            app_id                                           app_json  \\\n",
       "0  LlamaIndex_App1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "1  LlamaIndex_App1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "1  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_428bceed859a74951403887e04431b27   \n",
       "1  record_hash_2aab1c5faa398bff375bdfe7f6d897dd   \n",
       "\n",
       "                                          input  \\\n",
       "0  \"What is most interesting about this essay?\"   \n",
       "1  \"What is most interesting about this essay?\"   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"The most interesting aspect of this essay is ...    -   \n",
       "1  \"Based on the provided context, the most inter...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_428bceed859a7495140...   \n",
       "1  {\"record_id\": \"record_hash_2aab1c5faa398bff375...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "1  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2023-12-26T16:56:58.102181\", \"...   \n",
       "1  {\"start_time\": \"2023-12-26T17:33:45.205486\", \"...   \n",
       "\n",
       "                           ts  Answer Relevance  Context Relevance  \\\n",
       "0  2023-12-26T16:57:29.004522               0.8                0.2   \n",
       "1  2023-12-26T17:34:15.982798               1.0                1.0   \n",
       "\n",
       "   Groundedness:::full_doc_score  \\\n",
       "0                            0.0   \n",
       "1                            0.9   \n",
       "\n",
       "                              Answer Relevance_calls  \\\n",
       "0  [{'args': {'prompt': 'What is most interesting...   \n",
       "1  [{'args': {'prompt': 'What is most interesting...   \n",
       "\n",
       "                             Context Relevance_calls  \\\n",
       "0  [{'args': {'question': 'What is most interesti...   \n",
       "1  [{'args': {'question': 'What is most interesti...   \n",
       "\n",
       "                                  Groundedness_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'source': 'I remember taking the bo...       30             0   \n",
       "1  [{'args': {'source': 'I remember taking the bo...       30             0   \n",
       "\n",
       "   total_cost  \n",
       "0         0.0  \n",
       "1         0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View results in notebook\n",
    "tru.get_records_and_feedback(app_ids=[])[0] # pass an empty list of app_ids to get all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "Config file already exists. Skipping writing process.\n",
      "Credentials file already exists. Skipping writing process.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d6a37a85861403ba22f5cd12e712828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.20.13:8501 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:trulens_eval.feedback.groundedness:Feedback function `groundedness_measure` was renamed to `groundedness_measure_with_cot_reasons`. The new functionality of `groundedness_measure` function will no longer emit reasons as a lower cost option. It may have reduced accuracy due to not using Chain of Thought reasoning in the scoring.\n",
      "Feedback function `groundedness_measure` was renamed to `groundedness_measure_with_cot_reasons`. The new functionality of `groundedness_measure` function will no longer emit reasons as a lower cost option. It may have reduced accuracy due to not using Chain of Thought reasoning in the scoring.\n"
     ]
    }
   ],
   "source": [
    "#view results in dashboard\n",
    "tru.run_dashboard() # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
