{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦‘ Tru initialized with db url sqlite:///default.sqlite .\n",
      "ðŸ›‘ Secret keys may be written to the database. See the `database_redact_keys` option of `Tru` to prevent this.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_index.llms import AzureOpenAI\n",
    "from llama_index.embeddings import AzureOpenAIEmbedding\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "import logging\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.llms import Ollama\n",
    "import numpy as np\n",
    "from trulens_eval import TruLlama, Feedback, Tru, feedback\n",
    "from trulens_eval.tru_custom_app import instrument\n",
    "tru = Tru()\n",
    "\n",
    "load_dotenv('/Users/jeana/.env')\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout, level=logging.WARNING\n",
    ")  # logging.DEBUG for more verbose output\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_location = [r\"/Users/jeana/Retrieval-Augmented-Generation/LlamaIndex/paul_graham_essay.txt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modelException(Exception):\n",
    "    def __init__(self, invalid_value, allowed_values):\n",
    "        self.invalid_value = invalid_value\n",
    "        self.allowed_values = allowed_values\n",
    "        message = f\"Invalid value: {invalid_value}. Allowed values are: {', '.join(allowed_values)}\"\n",
    "        super().__init__(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Evaluator with Feedback functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedbacks():\n",
    "\n",
    "    ##### INITIALZE FEEDBACK FUNCTION(S)#######\n",
    "\n",
    "    # Initialize AzureOpenAI-based feedback function collection class:\n",
    "    azopenai = feedback.AzureOpenAI(\n",
    "                                    deployment_name=os.environ['OPENAI_DEPLOYMENT_NAME'],\n",
    "                                    api_key = os.environ['OPENAI_API_KEY'],\n",
    "                                    api_version=os.environ['OPENAI_DEPLOYMENT_VERSION'],\n",
    "                                    azure_endpoint=os.environ['OPENAI_DEPLOYMENT_ENDPOINT'],\n",
    "                                    # model = os.environ['OPENAI_MODEL_NAME']\n",
    "                                    )\n",
    "\n",
    "    # Question/answer relevance between overall question and answer.\n",
    "    f_qa_relevance = Feedback(azopenai.relevance, name = \"Answer Relevance\").on_input_output()\n",
    "\n",
    "    # Question/statement relevance between question and each context chunk.\n",
    "    f_qs_relevance = Feedback(azopenai.qs_relevance, name = \"Context Relevance\").on_input().on(\n",
    "        TruLlama.select_source_nodes().node.text\n",
    "    ).aggregate(np.mean)\n",
    "\n",
    "    # groundedness of output on the context\n",
    "    groundedness = feedback.Groundedness(\n",
    "                    # summarize_provider=azopenai, \n",
    "                    groundedness_provider=azopenai)\n",
    "    f_groundedness = Feedback(groundedness.groundedness_measure, name = \"Groundedness\").on(TruLlama.select_source_nodes().node.text).on_output()\n",
    "    \n",
    "    feedbacks=[f_groundedness, f_qa_relevance, f_qs_relevance]\n",
    "    \n",
    "    return feedbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:trulens_eval.feedback.provider.endpoint.openai:Arguments ['api_key', 'api_version', 'azure_endpoint'] are ignored as `client` was provided.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments ['api_key', 'api_version', 'azure_endpoint'] are ignored as `client` was provided.\n",
      "âœ… In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n",
      "âœ… In Context Relevance, input question will be set to __record__.main_input or `Select.RecordInput` .\n",
      "âœ… In Context Relevance, input statement will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n",
      "âœ… In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n"
     ]
    }
   ],
   "source": [
    "feedbacks = feedbacks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG():\n",
    "    llm_list = ['llama2', 'gpt3.5Turbo']\n",
    "    embedding_list = ['text-embedding-ada-002', 'sentence-transformers/all-mpnet-base-v2', \"BAAI/bge-small-en-v1.5\"]\n",
    "\n",
    "    def __init__(self, llm_name, embedding_model, feedbacks):   \n",
    "        if llm_name not in self.llm_list:\n",
    "            raise modelException(llm_name, self.llm_list)\n",
    "        if embedding_model not in self.embedding_list:\n",
    "            raise modelException(embedding_model, self.embedding_list)        \n",
    "\n",
    "        ## Getting the LLM for prediction\n",
    "        if llm_name == 'gpt3.5Turbo':\n",
    "            self.llm = AzureOpenAI(\n",
    "                    # model= os.environ['OPENAI_MODEL_NAME'],\n",
    "                    model = llm_name,\n",
    "                    deployment_name= os.environ['OPENAI_DEPLOYMENT_NAME'],\n",
    "                    api_key=os.environ['OPENAI_API_KEY'],\n",
    "                    azure_endpoint=os.environ['OPENAI_DEPLOYMENT_ENDPOINT'],\n",
    "                    api_version=os.environ['OPENAI_DEPLOYMENT_VERSION'],\n",
    "                )\n",
    "        elif llm_name == 'llama2':\n",
    "            self.llm = Ollama(model=\"llama2\")\n",
    "        \n",
    "        ## Gettting the embedding model\n",
    "        if embedding_model == 'text-embedding-ada-002':\n",
    "            self.embedding_model = AzureOpenAIEmbedding(\n",
    "                    # model=os.environ['OPENAI_EMBEDDING_MODEL_NAME'],\n",
    "                    model=embedding_model,\n",
    "                    deployment_name=os.environ['OPENAI_EMBEDDING_DEPLOYMENT_NAME'],\n",
    "                    api_key=os.environ['OPENAI_API_KEY'],\n",
    "                    azure_endpoint=os.environ['OPENAI_DEPLOYMENT_ENDPOINT'],\n",
    "                    api_version=os.environ['OPENAI_DEPLOYMENT_VERSION'],\n",
    "                )\n",
    "        elif embedding_model in ['sentence-transformers/all-mpnet-base-v2', \"BAAI/bge-small-en-v1.5\"]:\n",
    "            self.embedding_model = HuggingFaceEmbeddings(\n",
    "                    model_name=embedding_model)\n",
    "        \n",
    "        #Set service context, documents and Index\n",
    "        self.service_context = ServiceContext.from_defaults(embed_model=self.embedding_model, llm = self.llm)\n",
    "\n",
    "        self.documents = SimpleDirectoryReader(\n",
    "                    input_files=[r\"/Users/jeana/Retrieval-Augmented-Generation/LlamaIndex/paul_graham_essay.txt\"] #or just indicate the fullpath of the folder containing the data\n",
    "                                ).load_data()\n",
    "        self.index = VectorStoreIndex.from_documents(self.documents, service_context=self.service_context)\n",
    "\n",
    "    def query(self, query: str) -> str:\n",
    "        ### INSTRUMENT CHAIN FOR LOGGING WITH TRULENS\n",
    "\n",
    "        query_engine = self.index.as_query_engine()\n",
    "\n",
    "        tru_query_engine_recorder = TruLlama(query_engine,\n",
    "                app_id='LlamaIndex_App1',\n",
    "                feedbacks=feedbacks)\n",
    "\n",
    "        with tru_query_engine_recorder as recorder:\n",
    "            answer = query_engine.query(query)\n",
    "            print(answer.get_formatted_sources())\n",
    "            print(\"query was:\", query)\n",
    "            print(\"answer was:\", answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_name =  'llama2' #gpt3.5Turbo , llama2\n",
    "embedding_model = 'sentence-transformers/all-mpnet-base-v2' # text-embedding-ada-002 , sentence-transformers/all-mpnet-base-v2, local\n",
    "rag = RAG(llm_name, embedding_model, feedbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Source (Doc id: 8bb6e429-2e73-45aa-b52d-46b1f069d52c): I remember taking the boys to the coast on a sunny day in 2015 and figuring out how to deal with ...\n",
      "\n",
      "> Source (Doc id: 749ce9a8-3351-4832-a4f8-35e7cd742a26): One of the most conspicuous patterns I've noticed in my life is how well it has worked, for me at...\n",
      "query was: What is most interesting about this essay?\n",
      "answer was: The most interesting aspect of this essay is the author's reflection on how his choices and experiences have been shaped by his desire to work on things that are not prestigious, but instead genuinely interest him. He notes that when he finds himself drawn to something despite its lack of prestige, it's a sign that there's something real to be discovered there, and that he has the right kind of motives. He also shares how he and his friends have started their own investment firm, after becoming frustrated with the slow decision-making of venture capital firms.\n",
      "\n",
      "Overall, the essay provides a personal and introspective look at the author's approach to work and life, and how he prioritizes following his interests and passions over conventional expectations of success.\n",
      "WARNING:trulens_eval.feedback.groundedness:Feedback function `groundedness_measure` was renamed to `groundedness_measure_with_cot_reasons`. The new functionality of `groundedness_measure` function will no longer emit reasons as a lower cost option. It may have reduced accuracy due to not using Chain of Thought reasoning in the scoring.\n",
      "Feedback function `groundedness_measure` was renamed to `groundedness_measure_with_cot_reasons`. The new functionality of `groundedness_measure` function will no longer emit reasons as a lower cost option. It may have reduced accuracy due to not using Chain of Thought reasoning in the scoring.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "WARNING:trulens_eval.feedback.groundedness:Feedback function `groundedness_measure` was renamed to `groundedness_measure_with_cot_reasons`. The new functionality of `groundedness_measure` function will no longer emit reasons as a lower cost option. It may have reduced accuracy due to not using Chain of Thought reasoning in the scoring.\n",
      "Feedback function `groundedness_measure` was renamed to `groundedness_measure_with_cot_reasons`. The new functionality of `groundedness_measure` function will no longer emit reasons as a lower cost option. It may have reduced accuracy due to not using Chain of Thought reasoning in the scoring.\n"
     ]
    }
   ],
   "source": [
    "rag.query('What is most interesting about this essay?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_json</th>\n",
       "      <th>type</th>\n",
       "      <th>record_id</th>\n",
       "      <th>input</th>\n",
       "      <th>output</th>\n",
       "      <th>tags</th>\n",
       "      <th>record_json</th>\n",
       "      <th>cost_json</th>\n",
       "      <th>perf_json</th>\n",
       "      <th>ts</th>\n",
       "      <th>Answer Relevance</th>\n",
       "      <th>Context Relevance</th>\n",
       "      <th>Groundedness:::full_doc_score</th>\n",
       "      <th>Answer Relevance_calls</th>\n",
       "      <th>Context Relevance_calls</th>\n",
       "      <th>Groundedness_calls</th>\n",
       "      <th>latency</th>\n",
       "      <th>total_tokens</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LlamaIndex_App1</td>\n",
       "      <td>{\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...</td>\n",
       "      <td>RetrieverQueryEngine(llama_index.query_engine....</td>\n",
       "      <td>record_hash_428bceed859a74951403887e04431b27</td>\n",
       "      <td>\"What is most interesting about this essay?\"</td>\n",
       "      <td>\"The most interesting aspect of this essay is ...</td>\n",
       "      <td>-</td>\n",
       "      <td>{\"record_id\": \"record_hash_428bceed859a7495140...</td>\n",
       "      <td>{\"n_requests\": 0, \"n_successful_requests\": 0, ...</td>\n",
       "      <td>{\"start_time\": \"2023-12-26T16:56:58.102181\", \"...</td>\n",
       "      <td>2023-12-26T16:57:29.004522</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[{'args': {'prompt': 'What is most interesting...</td>\n",
       "      <td>[{'args': {'question': 'What is most interesti...</td>\n",
       "      <td>[{'args': {'source': 'I remember taking the bo...</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            app_id                                           app_json  \\\n",
       "0  LlamaIndex_App1  {\"tru_class_info\": {\"name\": \"TruLlama\", \"modul...   \n",
       "\n",
       "                                                type  \\\n",
       "0  RetrieverQueryEngine(llama_index.query_engine....   \n",
       "\n",
       "                                      record_id  \\\n",
       "0  record_hash_428bceed859a74951403887e04431b27   \n",
       "\n",
       "                                          input  \\\n",
       "0  \"What is most interesting about this essay?\"   \n",
       "\n",
       "                                              output tags  \\\n",
       "0  \"The most interesting aspect of this essay is ...    -   \n",
       "\n",
       "                                         record_json  \\\n",
       "0  {\"record_id\": \"record_hash_428bceed859a7495140...   \n",
       "\n",
       "                                           cost_json  \\\n",
       "0  {\"n_requests\": 0, \"n_successful_requests\": 0, ...   \n",
       "\n",
       "                                           perf_json  \\\n",
       "0  {\"start_time\": \"2023-12-26T16:56:58.102181\", \"...   \n",
       "\n",
       "                           ts  Answer Relevance  Context Relevance  \\\n",
       "0  2023-12-26T16:57:29.004522               0.8                0.2   \n",
       "\n",
       "   Groundedness:::full_doc_score  \\\n",
       "0                            0.0   \n",
       "\n",
       "                              Answer Relevance_calls  \\\n",
       "0  [{'args': {'prompt': 'What is most interesting...   \n",
       "\n",
       "                             Context Relevance_calls  \\\n",
       "0  [{'args': {'question': 'What is most interesti...   \n",
       "\n",
       "                                  Groundedness_calls  latency  total_tokens  \\\n",
       "0  [{'args': {'source': 'I remember taking the bo...       30             0   \n",
       "\n",
       "   total_cost  \n",
       "0         0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#View results in notebook\n",
    "tru.get_records_and_feedback(app_ids=[])[0] # pass an empty list of app_ids to get all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting dashboard ...\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876ef0fe444e48828c14ce886fda42f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valuâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard started at http://192.168.20.13:8501 .\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#view results in dashboard\n",
    "tru.run_dashboard() # open a local streamlit app to explore\n",
    "\n",
    "# tru.stop_dashboard() # stop if needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
