{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.llms import AzureOpenAI\n",
    "from llama_index.embeddings import AzureOpenAIEmbedding\n",
    "from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "import logging\n",
    "import sys\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv('/Users/jeana/.env')\n",
    "\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout, level=logging.WARNING\n",
    ")  # logging.DEBUG for more verbose output\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.environ['OPENAI_API_KEY']\n",
    "azure_endpoint = os.environ['OPENAI_DEPLOYMENT_ENDPOINT']\n",
    "api_version = os.environ['OPENAI_DEPLOYMENT_VERSION']\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    model= os.environ['OPENAI_MODEL_NAME'],\n",
    "    deployment_name= os.environ['OPENAI_DEPLOYMENT_NAME'],\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=os.environ['OPENAI_EMBEDDING_MODEL_NAME'],\n",
    "    deployment_name=os.environ['OPENAI_EMBEDDING_DEPLOYMENT_NAME'],\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index import set_global_service_context\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=embed_model,\n",
    ")\n",
    "\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://riskpocai-jpe.openai.azure.com//openai/deployments/AZAIEMBTXTRisk-EDU/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://riskpocai-jpe.openai.azure.com//openai/deployments/AZAIEMBTXTRisk-EDU/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://riskpocai-jpe.openai.azure.com//openai/deployments/AZAIEMBTXTRisk-EDU/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://riskpocai-jpe.openai.azure.com//openai/deployments/AZAIEMBTXTRisk-EDU/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://riskpocai-jpe.openai.azure.com//openai/deployments/AZAIEMBTXTRisk-EDU/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://riskpocai-jpe.openai.azure.com//openai/deployments/AZAIEMBTXTRisk-EDU/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader(\n",
    "    input_files=[r\"/Users/jeana/Retrieval-Augmented-Generation/LlamaIndex/paul_graham_essay.txt\"] #or just indicate the fullpath of the folder containing the data\n",
    ").load_data()\n",
    "index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://riskpocai-jpe.openai.azure.com//openai/deployments/AZAIEMBTXTRisk-EDU/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://riskpocai-jpe.openai.azure.com//openai/deployments/AZAIEMBTXTRisk-EDU/embeddings?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://riskpocai-jpe.openai.azure.com//openai/deployments/AZAIPOCRisk-EDU/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://riskpocai-jpe.openai.azure.com//openai/deployments/AZAIPOCRisk-EDU/chat/completions?api-version=2023-07-01-preview \"HTTP/1.1 200 OK\"\n",
      "> Source (Doc id: a5a1bdbc-e896-4acb-a37e-12ab851f4a45): One of the most conspicuous patterns I've noticed in my life is how well it has worked, for me at...\n",
      "\n",
      "> Source (Doc id: 83cbc069-3e87-4f0a-b82d-c57f7c712766): I remember taking the boys to the coast on a sunny day in 2015 and figuring out how to deal with ...\n",
      "query was: What is most interesting about this essay?\n",
      "answer was: The most interesting aspect of this essay is the author's reflection on their personal experiences and how they have shaped their perspective on work and life. The author discusses their observations about the value of working on things that may not be prestigious, but are personally meaningful. They also share anecdotes about their own journey, including their involvement in various projects, their relationship with their partner, and their decision to start their own investment firm. These personal insights and reflections make the essay engaging and relatable.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is most interesting about this essay?\"\n",
    "query_engine = index.as_query_engine()\n",
    "answer = query_engine.query(query)\n",
    "\n",
    "print(answer.get_formatted_sources())\n",
    "print(\"query was:\", query)\n",
    "print(\"answer was:\", answer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
